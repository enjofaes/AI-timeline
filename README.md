# AI-timeline
This Timeline is open for everyone. The timeline is a proposition, based on a course I'm following from GARP (Risk and AI). 

**1900s: Foundations and Early AI Research**
-	1936: Alan Turing introduces the concept of the Turing Machine, a theoretical foundation for modern computing.
-	1941: Alan Turing begins contemplating AI during his work at Bletchley Park.
-	1943: Warren McCulloch and Walter Pitts publish “A Logical Calculus of the Ideas Immanent in Nervous Activity,” a foundational work in neural networks.
-	1947: The Nuremberg Code introduces informed consent and ethics in human experimentation.
-	1948: The Universal Declaration of Human Rights (UDHR) is adopted.
-	1949: Donald Hebb publishes The Organization of Behavior, proposing a theory of associative learning in neural networks (Hebbian learning).
-	1950:
  - Alan Turing publishes “Computing Machinery and Intelligence,” introducing the Turing Test.
  - Isaac Asimov introduces The Three Laws of Robotics.
-	1955: Allen Newell, Herbert Simon, and Cliff Shaw develop the Logic Theorist, an AI program that proves many theorems in Principia Mathematica.
-	1956: The Dartmouth Conference, led by John McCarthy, coins the term Artificial Intelligence.
-	1958:
  - Frank Rosenblatt introduces the Perceptron, one of the first neural network models.
  - Rosenblatt’s approach uses probability theory instead of symbolic logic, marking a departure from earlier methods.
-	1959: Arthur Samuel develops a self-learning program for checkers.
-	1969: Marvin Minsky and Seymour Papert critique single-layer perceptrons in their book Perceptrons, halting neural network research for years.
-	1982: Introduction of Principal Component Analysis (PCA) for dimensionality reduction and data analysis.
-	1986:
  - David Rumelhart, James McClelland, and the PDP Group popularize backpropagation learning in their Parallel Distributed Processing volumes, reviving neural networks.
  - The Connectionism Movement emphasizes parallel distributed processing, providing biological inspiration for AI.
-	1997: IBM’s Deep Blue defeats Garry Kasparov in chess.
- 1998: Yann LeCun develops LeNet-5, a convolutional neural network (CNN) for handwritten digit recognition.

**2000s: Early AI Developments and Ethical Considerations**
- 2001: The film "A.I. Artificial Intelligence" is released: Bringing AI and its ethical implications into mainstream public discourse.
- 	2004:
  - ARPA Grand Challenge: The first competition for autonomous vehicles; although no vehicle completed the course, it spurred advancements in self-driving technology.
- 2005:
  - Stanford's "Stanley" wins the DARPA Grand Challenge: Successfully navigating 132 miles autonomously.
  - Ray Kurzweil publishes "The Singularity is Near": Discussing the future of AI and potential risks of superintelligence.
- 2006:
  - Geoffrey Hinton introduces Deep Belief Networks (DBNs), reigniting interest in deep learning.
  - Fei-Fei Li founds ImageNet: A large visual database crucial for advancing computer vision.
  - AI begins expanding into speech and image recognition.
- 2009:
  - Google starts developing self-driving cars: Marking significant investment in autonomous vehicle technology.
  - The Machine Intelligence Research Institute (MIRI) is founded: Focusing on AI safety and risk.

**2010s: Deep Learning Foundations and Emerging Risks**
- 2011:
  - IBM's Watson wins Jeopardy!: Demonstrating advanced natural language processing capabilities.
  - Apple introduces Siri: Popularizing AI-powered virtual assistants and raising privacy considerations.
-	2012:
  - AlexNet, created by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, wins the ImageNet competition, drastically reducing error rates.
  - Neural networks become dominant in computer vision benchmarks.
  - Google Brain project recognizes cats in YouTube videos: Advancing unsupervised learning capabilities.
-	2013:
  -	DeepMind’s Atari Game AI surpasses human performance in games like Pong and Breakout, using deep reinforcement learning.
  - Boston Dynamics showcases advanced robots like Atlas: Raising ethical concerns about robotics in military applications.
- 2014:
  - Google acquires DeepMind.
  - Ian Goodfellow introduces Generative Adversarial Networks (GANs), revolutionizing creative AI.
  - Amazon launches Alexa and the Echo: Bringing voice-activated AI assistants into homes.
  - Elon Musk and Stephen Hawking warn about AI risks: Highlighting potential existential threats from advanced AI.
  - The Future of Life Institute is founded: Aiming to mitigate existential risks, including those from AI.

**2015–2017: Early Ethical and Governance Milestones**
- 2015:
  - OpenAI is founded: With the mission to ensure that artificial general intelligence (AGI) benefits all of humanity.
  - The Asilomar Conference on Beneficial AI: Organized by the Future of Life Institute to discuss AI safety and ethics.
  - Publication of "Superintelligence" by Nick Bostrom: Raising awareness about the long-term risks of advanced AI.
- 2016:
  - The IEEE launches the Global Initiative on Ethics of Autonomous and Intelligent Systems: Aiming to integrate ethical considerations into AI and autonomous systems.
  - Microsoft's Tay chatbot incident: Tay is taken offline after generating inappropriate content, highlighting risks of AI in social media.
  - Tesla's Autopilot involved in a fatal crash: Raising concerns about the safety of autonomous driving systems.
  - DeepMind's AlphaGo defeats Lee Sedol 4-1 in Go: Showcasing advanced AI capabilities and sparking ethical discussions.
- 2017:
  - Google publishes "Attention is all you need": about Transformers and LLMs 
  - Asilomar AI Principles are published: A set of 23 guidelines to guide AI research and development towards beneficial outcomes.
  - China announces its Next Generation AI Development Plan: Emphasizing AI leadership and ethical considerations.
  - The Partnership on AI becomes operational: Founded by companies like Amazon, Apple, Google, Facebook, IBM, and Microsoft to study and formulate best practices on AI technologies.
  - DeepMind develops AlphaGo Zero and AlphaZero: AI systems that learn without human data, raising discussions about self-learning AI.

**2018–2020: Strengthening Governance and Ethical Frameworks**
-	2018:
  -	The General Data Protection Regulation (GDPR) comes into effect in the EU: Imposing strict rules on data protection and privacy, impacting AI systems handling personal data.
  -	The European Commission establishes the High-Level Expert Group on AI (AI HLEG): Tasked with developing guidelines for trustworthy AI.
  -	Amazon's AI recruiting tool is found biased against women: Leading to its abandonment and raising concerns about bias in AI.
  -	Uber's self-driving car accident in Arizona: Resulting in a pedestrian fatality and highlighting risks of autonomous vehicles.
  -	IBM releases the AI Fairness 360 toolkit: An open-source library to detect and mitigate bias in machine learning models.
  -	Cambridge Analytica scandal: Exposes misuse of data and AI in influencing elections, raising concerns over data privacy and AI's role in society.
  -	Google develops BERT: Advancing natural language processing capabilities.
  -	DeepMind's AlphaFold makes significant advances in protein folding prediction: Highlighting AI's potential in biology and ethical considerations in biotechnology.
- 2019:
  - AI HLEG publishes the Ethics Guidelines for Trustworthy AI: Providing a framework for developing and deploying AI systems that are lawful, ethical, and robust.
  - The U.S. Department of Defense releases its AI Strategy: Emphasizing the ethical use of AI in defense applications.
  - San Francisco bans facial recognition technology: Becoming the first major U.S. city to prohibit its use by law enforcement.
  - The OECD adopts the Principles on AI: The first international standards agreed upon by governments for the responsible stewardship of trustworthy AI.
  - OpenAI transitions to a "capped-profit" model: Raising discussions about AI commercialization and ethics.
- 2020:
  - UNESCO begins work on global standards for AI ethics: Initiating the development of an international framework.
  - IBM, Amazon, and Microsoft halt sales of facial recognition technology to police: Due to concerns over bias and misuse.
  - Publication of "Tools and Weapons" by Brad Smith and Carol Ann Browne: Discussing the challenges of the digital age, including AI ethics and regulation.
  - The AI Incident Database is launched: A platform collecting reports of AI failures and harms to improve transparency and safety.
  - OpenAI releases GPT-3: Dramatically advancing NLP capabilities and leading to discussions on AI-generated content and its risks.
  - DeepMind's AlphaFold 2 solves the protein folding problem: Recognized as a significant scientific breakthrough.

**2021–2024: Advancements in AI Ethics and Regulation, as well as in AI itself**
-	2021:
  -	UNESCO adopts the Recommendation on the Ethics of Artificial Intelligence: The first global standard-setting instrument on AI ethics.
  -	The U.S. establishes the National AI Initiative Office: Coordinating federal AI research and policy to ensure leadership in AI while addressing associated risks.
  -	Google fires AI ethics researcher Timnit Gebru: Sparking global discussions on ethics in AI research, diversity, and corporate responsibility.
  -	The EU releases the draft of the AI Act: Proposing a regulatory framework for AI, focusing on risk management and fundamental rights.
  -	Advancements in AI explainability and interpretability: Efforts to make AI systems more transparent, addressing risks associated with black-box models.
-	2022:
  - Canada introduces the Artificial Intelligence and Data Act (AIDA): Aiming to regulate AI systems and protect individuals from harm.
  - The UK publishes its National AI Strategy: Outlining plans for AI governance, innovation, and ethical deployment.
  - Facebook's AI mislabels a video, leading to apologies: Highlighting ongoing challenges with AI bias and content moderation.
  - The U.S. National Institute of Standards and Technology (NIST) begins developing the AI Risk Management Framework: To improve the ability to incorporate trustworthiness considerations into AI systems.
-	2023:
  -	March 2023, Italy temporarily bans ChatGPT: Due to concerns over data privacy and compliance with GDPR. But restored EoM.
  -	NIST releases the AI Risk Management Framework (AI RMF): Providing guidelines to manage risks associated with AI systems.
  -	The EU continues refining the AI Act: Progressing towards implementing a comprehensive AI regulatory framework.
  -	The White House announces the Blueprint for an AI Bill of Rights: Aiming to protect the American public in the age of AI.
  -	Major tech companies commit to AI safety measures: In response to increasing capabilities of AI systems and public concern.
  -	Generative AI models like GPT-4 are released: Leading to widespread discussions on AI's impact and the need for regulation.
  -	Advancements in quantum AI research: Raising new considerations for AI capabilities and associated risks.
-	2024:
  - The EU AI Act comes into effect, establishing comprehensive regulations for artificial intelligence within the European Union.
  - Google releases Gemini AI, advancing multimodal generative AI capabilities.
  - OpenAI introduces Sora, a video generation model, and O1-preview and O1-mini, available for Plus users, enhancing AI accessibility.
  - Advanced voice mode is launched, improving AI's conversational abilities.
  - Google unveils Notebook LM, an AI-driven tool for automated podcast creation.
  - Apple introduces Apple Intelligence, a suite of AI tools integrated into iOS 18, iPadOS 18, and macOS Sequoia, emphasizing on-device processing and user privacy.
  - Tesla rolls out Full Self-Driving (FSD) version 13, marking significant advancements in autonomous vehicle technology.
  - The Browser Company announces Dia, an AI-centered web browser designed to simplify web tasks through embedded AI tools, set to launch in early 2025.
  - Insitro leverages machine learning to expedite drug discovery, aiming to develop drugs more efficiently and affordably.
  - AWS plans significant AI updates poised to drive notable advancements, emphasizing AI as an ongoing foundational technology.
  - Nvidia continues to dominate the AI chip market, with its GPUs central to AI advancements, while companies like Google develop their own AI chips to reduce reliance on Nvidia. 
  - AI-based studies reveal that fingerprints from different fingers of the same person share strong detectable similarities, challenging the uniqueness of fingerprints. 
  - Large language models demonstrate superior persuasive abilities compared to humans when using personal information, highlighting AI's potential in tailored communication.
  - LAION releases BUD-E, a fully open-source voice assistant, contributing to the open AI ecosystem.
  - Researchers develop an AI-powered waste-sorting robot capable of identifying over 500 waste categories, enhancing recycling efficiency.
  - The chatbot Grok is made open source to a substantial extent, promoting transparency and collaboration in AI development. 
